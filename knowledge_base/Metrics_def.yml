version: 2

# Business Metrics Configuration
# This file defines business metrics for analytics and reporting
# Organized by domain: CS (Customer Support) and Transfers

metrics:
  # =============================================================================
  # CUSTOMER SUPPORT (CS) DOMAIN METRICS
  # =============================================================================
  
  # 1. Metric Name: Adherence
  # Definition: Amount of time spent in adherent state relative to productive time, used to measure agent schedule compliance.
  # 
  # 2. Calculation Logic:
  # sum(adherence_productive_time) / scheduled_productive_hours
  #
  # 3. Data Source(s): dim_agent_scheduling_daily (columns: adherence_productive_time, scheduled_productive_time)
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: adherence
    label: Adherence
    model: ref('dim_agent_scheduling_daily')
    description: >
      Amount of time spent in adherent state relative to productive time.
      Used to measure agent schedule compliance.
    type: ratio
    sql: sum(1.0000 * adherence_productive_time) / nullif({{ metric('scheduled_productive_hours') }}, 0)
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: agent_performance

  # 1. Metric Name: Scheduled Productive Hours
  # Definition: Total scheduled productive hours for agents
  # 
  # 2. Calculation Logic:
  # (scheduled_productive_time in seconds) / (3600 seconds per hour)
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: scheduled_productive_time)
  #
  # 4. Units: Hours
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: scheduled_productive_hours
    label: Productive Hours
    model: ref('dim_cs_agent_scorecard')
    description: Total scheduled productive hours for agents
    type: sum
    sql: (1.0/(60*60)) * scheduled_productive_time
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: agent_performance

  # 1. Metric Name: Occupancy
  # Definition: Proportion of time spent in occupancy state relative to productive scheduled time
  # 
  # 2. Calculation Logic:
  # sum(occupancy_productive_time) / sum(scheduled_productive_time)
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: occupancy_productive_time, scheduled_productive_time)
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: occupancy
    label: Occupancy Rate
    model: ref('dim_cs_agent_scorecard')
    description: Proportion of time spent in occupancy state relative to productive scheduled time
    type: ratio
    sql: sum(1.0000 * occupancy_productive_time) / nullif(sum(scheduled_productive_time), 0)
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: agent_performance

  # 1. Metric Name: First Contact Resolution (FCR)
  # Definition: The percentage of customer support tickets that are resolved during the first interaction with the support team, without requiring follow-up contacts.
  # 
  # 2. Calculation Logic:
  # (COUNT(DISTINCT tickets resolved on first contact)) / (COUNT(DISTINCT total resolvable tickets created in the period)) * 100
  # - Tickets resolved on first contact: ticket_id from dim_ticket_summary_slim where resolution_contacts = 1 AND status IN ('solved', 'closed')
  # - Total resolvable tickets: ticket_id from dim_ticket_summary_slim where status IN ('solved', 'closed', 'open', 'pending')
  # - Period: Based on ticket_created_at
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: ticket_id, resolution_contacts, status, ticket_created_at)
  #
  # 4. Units: Percentage (%)
  #
  # 5. Dimensions: Can be analyzed by date, channel, L1 agent, L1 team.
  - name: first_contact_resolution_rate
    label: First Contact Resolution Rate
    model: ref('dim_ticket_summary_slim')
    description: Percentage of tickets resolved on first contact without requiring follow-ups
    type: ratio
    sql: sum(case when resolution_contacts = 1 and status in ('solved', 'closed') then 1 else 0 end) / 
         nullif(sum(case when status in ('solved', 'closed', 'open', 'pending') then 1 else 0 end), 0)
    timestamp: ticket_created_at
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: performance

  # 1. Metric Name: Chat Acceptance Rate
  # Definition: Rate of chats accepted relative to total chats assigned
  # 
  # 2. Calculation Logic:
  # sum(accepted_pings_chat) / sum(assigned_and_accepted_pings_chat)
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: accepted_pings_chat, assigned_and_accepted_pings_chat)
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: chat_acceptance_rate
    label: Chat Acceptance Rate
    model: ref('dim_cs_agent_scorecard')
    description: Rate of chats accepted relative to total chats assigned
    type: ratio
    sql: sum(1.0000 * accepted_pings_chat) / nullif(sum(1.0000 * assigned_and_accepted_pings_chat), 0)
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: chat_performance

  # 1. Metric Name: Chat Readiness Rate
  # Definition: Proportion of time spent in chat ready state relative to scheduled chat time
  # 
  # 2. Calculation Logic:
  # sum(chat_online_time) / sum(scheduled_time_chat)
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: chat_online_time, scheduled_time_chat)
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: chat_readiness_rate
    label: Chat Readiness Rate
    model: ref('dim_cs_agent_scorecard')
    description: Proportion of time spent in chat ready state relative to scheduled chat time
    type: ratio
    sql: (1.0000 * sum(chat_online_time)) / nullif(sum(scheduled_time_chat), 0)
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: chat_performance

  # 1. Metric Name: Chat Volume
  # Definition: Total number of chats created
  # 
  # 2. Calculation Logic:
  # COUNT(interaction_id)
  #
  # 3. Data Source(s): prep_chat_ticket_interactions (columns: interaction_id, chat_start_at)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by interaction, ticket, agent, team, client, day, week, month, quarter, year
  - name: chat_volume
    label: Chat Volume
    model: ref('prep_chat_ticket_interactions')
    description: Total number of chats created
    type: count
    sql: interaction_id
    timestamp: chat_start_at
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - interaction
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: volume

  # 1. Metric Name: Missed Chats
  # Definition: Count of chat pings that were not accepted
  # 
  # 2. Calculation Logic:
  # assigned_pings_chat - assigned_and_accepted_pings_chat
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: assigned_pings_chat, assigned_and_accepted_pings_chat)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: missed_chats
    label: Missed Chats
    model: ref('dim_cs_agent_scorecard')
    description: Count of chat pings that were not accepted
    type: sum
    sql: assigned_pings_chat - assigned_and_accepted_pings_chat
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: chat_performance

  # 1. Metric Name: Call Volume
  # Definition: Total number of calls received
  # 
  # 2. Calculation Logic:
  # COUNT(interaction_id)
  #
  # 3. Data Source(s): prep_phone_ticket_interactions (columns: interaction_id, interaction_start_at)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by interaction, ticket, agent, team, client, day, week, month, quarter, year
  - name: call_volume
    label: Call Volume
    model: ref('prep_phone_ticket_interactions')
    description: Total number of calls received
    type: count
    sql: interaction_id
    timestamp: interaction_start_at
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - interaction
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: volume

  # 1. Metric Name: Phone Readiness
  # Definition: Proportion of time spent in any state other than phone not ready state relative to scheduled phone time
  # 
  # 2. Calculation Logic:
  # 1 - ((sum(notready_time)) / sum(scheduled_time_phone))
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: notready_time, scheduled_time_phone)
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: phone_readiness
    label: Phone Readiness Rate
    model: ref('dim_cs_agent_scorecard')
    description: Proportion of time spent in any state other than phone not ready state relative to scheduled phone time
    type: ratio
    sql: 1 - ((1.0000 * sum(notready_time)) / nullif(sum(scheduled_time_phone), 0))
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: phone_performance

  # 1. Metric Name: On Call Rate
  # Definition: Proportion of time spent in on call state relative to productive scheduled phone time
  # 
  # 2. Calculation Logic:
  # sum(on_call_time) / sum(scheduled_time_phone)
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: on_call_time, scheduled_time_phone)
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by agent, team, day, week, month, quarter, year
  - name: on_call_rate
    label: On Call Rate
    model: ref('dim_cs_agent_scorecard')
    description: Proportion of time spent in on call state relative to productive scheduled phone time
    type: ratio
    sql: (1.0000 * sum(on_call_time)) / nullif(sum(scheduled_time_phone), 0)
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - agent
      - team
    meta:
      domain: cs
      category: phone_performance

  # 1. Metric Name: Average CSAT Score
  # Definition: Average customer satisfaction score received
  # 
  # 2. Calculation Logic:
  # AVG(csat_score_given)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: csat_score_given, last_solved_date)
  #
  # 4. Units: Score (typically 1-5)
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: avg_csat_score
    label: Average CSAT Score
    model: ref('dim_ticket_summary_slim')
    description: Average customer satisfaction score received
    type: average
    sql: csat_score_given
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: satisfaction

  # 1. Metric Name: CSAT Responses
  # Definition: Total number of CSAT responses received
  # 
  # 2. Calculation Logic:
  # COUNT(case when csat_score_given is not null then csat_score_given else null end)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: csat_score_given, last_solved_date)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: csat_responses
    label: CSAT Responses
    model: ref('dim_ticket_summary_slim')
    description: Total number of CSAT responses received
    type: count
    sql: case when csat_score_given is not null then csat_score_given else null end
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: satisfaction

  # 1. Metric Name: CSAT 5 Count
  # Definition: Total number of CSAT responses with a score of 5
  # 
  # 2. Calculation Logic:
  # COUNT(case when csat_score_given = 5 then csat_score_given else null end)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: csat_score_given, last_solved_date)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: csat_score_5
    label: CSAT 5 Count
    model: ref('dim_ticket_summary_slim')
    description: Total number of CSAT responses with a score of 5
    type: count
    sql: case when csat_score_given = 5 then csat_score_given else null end
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: satisfaction

  # 1. Metric Name: CSAT 5 Rate
  # Definition: Proportion of CSAT scores that are 5 (excellent)
  # 
  # 2. Calculation Logic:
  # csat_score_5 / csat_responses
  #
  # 3. Data Source(s): Derived from csat_score_5 and csat_responses metrics
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: csat_5_rate
    label: CSAT 5 Rate
    model: ref('dim_ticket_summary_slim')
    description: Proportion of CSAT scores that are 5 (excellent)
    type: ratio
    sql: {{ metric('csat_score_5') }} / nullif({{ metric('csat_responses') }}, 0)
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: satisfaction

  # 1. Metric Name: CSAT Coverage Rate
  # Definition: Percentage of all solved tickets with a CSAT response
  # 
  # 2. Calculation Logic:
  # csat_responses / tickets_solved
  #
  # 3. Data Source(s): Derived from csat_responses and tickets_solved metrics
  #
  # 4. Units: Ratio (0-1)
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: csat_coverage_rate
    label: CSAT Coverage Rate
    model: ref('dim_ticket_summary_slim')
    description: Percentage of all solved tickets with a CSAT response
    type: ratio
    sql: {{ metric('csat_responses') }} / nullif({{ metric('tickets_solved') }}, 0)
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: satisfaction

  # 1. Metric Name: Tickets Solved
  # Definition: Total number of tickets solved
  # 
  # 2. Calculation Logic:
  # COUNT(case when status in ('solved', 'closed') then ticket_id else null end)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: ticket_id, status, last_solved_date)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: tickets_solved
    label: Solved Tickets
    model: ref('dim_ticket_summary_slim')
    description: Total number of tickets solved
    type: count
    sql: case when status in ('solved', 'closed') then ticket_id else null end
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: tickets

  # 1. Metric Name: Ticket Count
  # Definition: Total number of tickets created
  # 
  # 2. Calculation Logic:
  # COUNT(ticket_id)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: ticket_id, ticket_created_at)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: ticket_count
    label: Total Tickets
    model: ref('dim_ticket_summary_slim')
    description: Total number of tickets created
    type: count
    sql: ticket_id
    timestamp: ticket_created_at
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: tickets

  # 1. Metric Name: Average Handle Time
  # Definition: Average time to handle and resolve tickets
  # 
  # 2. Calculation Logic:
  # AVG(handle_time)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: handle_time, last_solved_date)
  #
  # 4. Units: Time (typically seconds or minutes)
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: avg_handle_time
    label: Average Handle Time
    model: ref('dim_ticket_summary_slim')
    description: Average time to handle and resolve tickets
    type: average
    sql: handle_time
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: performance

  # 1. Metric Name: Average First Response Time
  # Definition: Average time from ticket creation to first agent response
  # 
  # 2. Calculation Logic:
  # AVG(avg_first_response_time)
  #
  # 3. Data Source(s): dim_ticket_summary_slim (columns: avg_first_response_time, last_solved_date)
  #
  # 4. Units: Time (typically seconds or minutes)
  #
  # 5. Dimensions: Can be analyzed by ticket, agent, team, client, day, week, month, quarter, year
  - name: avg_first_response_time
    label: Average First Response Time
    model: ref('dim_ticket_summary_slim')
    description: Average time from ticket creation to first agent response
    type: average
    sql: avg_first_response_time
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: performance

  # 1. Metric Name: Average QA Score
  # Definition: Average quality assurance score received
  # 
  # 2. Calculation Logic:
  # AVG(avg_qa_score)
  #
  # 3. Data Source(s): prep_cx_level_ai_qa_scores (columns: avg_qa_score, last_solved_date)
  #
  # 4. Units: Score (typically percentage or scale, e.g., 0-100)
  #
  # 5. Dimensions: Can be analyzed by interaction, ticket, agent, team, client, day, week, month, quarter, year
  - name: avg_qa_score
    label: Average QA Score
    model: ref('prep_cx_level_ai_qa_scores')
    description: Average quality assurance score received
    type: average
    sql: avg_qa_score
    timestamp: last_solved_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - interaction
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: quality

  # 1. Metric Name: QA Evaluations
  # Definition: Number of interactions evaluated by QA
  # 
  # 2. Calculation Logic:
  # SUM(qa_count)
  #
  # 3. Data Source(s): dim_cs_agent_scorecard (columns: qa_count, summary_date)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by interaction, ticket, agent, team, client, day, week, month, quarter, year
  - name: qa_count
    label: QA Evaluations
    model: ref('dim_cs_agent_scorecard')
    description: Number of interactions evaluated by QA
    type: sum
    sql: qa_count
    timestamp: summary_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - interaction
      - ticket
      - agent
      - team
      - client
    meta:
      domain: cs
      category: quality

  # 1. Metric Name: Web Interaction Volume
  # Definition: Total number of web interactions
  # 
  # 2. Calculation Logic:
  # COUNT(interaction_id)
  #
  # 3. Data Source(s): prep_web_ticket_interactions (columns: interaction_id, interacted_at)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by interaction, day, week, month, quarter, year
  - name: web_volume
    label: Web Interaction Volume
    model: ref('prep_web_ticket_interactions')
    description: Total number of web interactions
    type: count
    sql: interaction_id
    timestamp: interacted_at
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - interaction
    meta:
      domain: cs
      category: volume

  # =============================================================================
  # TRANSFERS DOMAIN METRICS
  # =============================================================================

  # 1. Metric Name: Account Value
  # Definition: Value of the client's account involved in the transfer, indicating business importance and risk level
  # 
  # 2. Calculation Logic:
  # SUM(account_value)
  #
  # 3. Data Source(s): money_movement__dim_accounts (columns: account_value, transitioned_date)
  #
  # 4. Units: Currency (USD)
  #
  # 5. Dimensions: Can be analyzed by transfer, day, week, month, quarter, year
  - name: account_value
    label: Account Value
    model: ref('money_movement__dim_accounts')
    description: >
      Value of the client's account involved in the transfer, 
      indicating business importance and risk level.
    type: sum
    sql: account_value
    timestamp: transitioned_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - transfer
    meta:
      domain: transfers
      category: financial

  # 1. Metric Name: Transfer Duration (Days)
  # Definition: Total duration of the full transfer lifecycle from first state to terminal state
  # 
  # 2. Calculation Logic:
  # AVG(datediff('days', transfer_created_at, cal_mapping_end_date::date))
  #
  # 3. Data Source(s): money_movement__fct_institutional_transfer_state_histories 
  #                    (columns: transfer_created_at, cal_mapping_end_date, transitioned_date)
  #
  # 4. Units: Days
  #
  # 5. Dimensions: Can be analyzed by transfer, day, week, month, quarter, year
  - name: transfer_duration_days
    label: Transfer Duration (Days)
    model: ref('money_movement__fct_institutional_transfer_state_histories')
    description: >
      Total duration of the full transfer lifecycle from 
      first state to terminal state.
    type: average
    sql: datediff('days', transfer_created_at, cal_mapping_end_date::date)
    timestamp: transitioned_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - transfer
    meta:
      domain: transfers
      category: performance

  # 1. Metric Name: Days in State
  # Definition: Number of days the transfer has remained in its current status without transitioning to a new state
  # 
  # 2. Calculation Logic:
  # SUM(datediff('days', transitioned_date, next_state_transitioned_at))
  #
  # 3. Data Source(s): money_movement__fct_institutional_transfer_state_histories 
  #                    (columns: transitioned_date, next_state_transitioned_at)
  #
  # 4. Units: Days
  #
  # 5. Dimensions: Can be analyzed by transfer, day, week, month, quarter, year
  - name: days_in_state
    label: Days in Current State
    model: ref('money_movement__fct_institutional_transfer_state_histories')
    description: >
      Number of days the transfer has remained in its current 
      status without transitioning to a new state.
    type: sum
    sql: datediff('days', transitioned_date, next_state_transitioned_at)
    timestamp: transitioned_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - transfer
    meta:
      domain: transfers
      category: performance

  # 1. Metric Name: SLA Breaches
  # Definition: Count of transfers that have breached SLA thresholds
  # 
  # 2. Calculation Logic:
  # COUNT(case when sla_flag = 1 then transfer_id else null end)
  #
  # 3. Data Source(s): money_movement__fct_institutional_transfer_state_histories 
  #                    (columns: sla_flag, transfer_id, transitioned_date)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by transfer, day, week, month, quarter, year
  - name: sla_breach_count
    label: SLA Breaches
    model: ref('money_movement__fct_institutional_transfer_state_histories')
    description: Count of transfers that have breached SLA thresholds
    type: count
    sql: case when sla_flag = 1 then transfer_id else null end
    timestamp: transitioned_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - transfer
    meta:
      domain: transfers
      category: sla

  # 1. Metric Name: State-Level SLA Breaches
  # Definition: Count of state-level SLA breaches
  # 
  # 2. Calculation Logic:
  # COUNT(case when state_sla_flag = 1 then transfer_id else null end)
  #
  # 3. Data Source(s): money_movement__fct_institutional_transfer_state_histories 
  #                    (columns: state_sla_flag, transfer_id, transitioned_date)
  #
  # 4. Units: Count
  #
  # 5. Dimensions: Can be analyzed by transfer, day, week, month, quarter, year
  - name: state_sla_breach_count
    label: State-Level SLA Breaches
    model: ref('money_movement__fct_institutional_transfer_state_histories')
    description: Count of state-level SLA breaches
    type: count
    sql: case when state_sla_flag = 1 then transfer_id else null end
    timestamp: transitioned_date
    time_grains: [day, week, month, quarter, year]
    dimensions:
      - transfer
    meta:
      domain: transfers
      category: sla
